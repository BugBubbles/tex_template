@inproceedings{kaiser_towards_2016,
	location = {San Francisco, {CA}},
	title = {Towards a framework for end-to-end control of a simulated vehicle with spiking neural networks},
	isbn = {978-1-5090-4616-4},
	url = {https://ieeexplore.ieee.org/document/7862386/},
	doi = {10/gtqp7p},
	abstract = {Spiking neural networks are in theory more computationally powerful than rate-based neural networks often used in deep learning architectures. However, unlike rate-based neural networks, it is yet unclear how to train spiking networks to solve complex problems. There are still no standard algorithms and it is preventing roboticists to use spiking networks, yielding a lack of Neurorobotics applications. The contribution of this paper is twofold. First, we present a modular framework to evaluate neural self-driving vehicle applications. It provides a visual encoder from camera images to spikes inspired by the silicon retina ({DVS}), and a steering wheel decoder based on an agonist antagonist muscle model. Secondly, using this framework, we demonstrate a spiking neural network which controls a vehicle end-to-end for lane following behavior. The network is feed-forward and relies on hand-crafted feature detectors. In future work, this framework could be used to design more complex networks and use the evaluation metrics for learning.},
	eventtitle = {2016 {IEEE} International Conference on Simulation, Modeling and Programming for Autonomous Robots ({SIMPAR})},
	pages = {127--134},
	booktitle = {2016 {IEEE} International Conference on Simulation, Modeling, and Programming for Autonomous Robots ({SIMPAR})},
	publisher = {{IEEE}},
	author = {Kaiser, Jacques and Tieck, J. Camilo Vasquez and Hubschneider, Christian and Wolf, Peter and Weber, Michael and Hoff, Michael and Friedrich, Alexander and Wojtasik, Konrad and Roennau, Arne and Kohlhaas, Ralf and Dillmann, Rudiger and Zollner, J. Marius},
	urldate = {2024-04-08},
	date = {2016-12},
	langid = {english},
	note = {40 citations (Crossref/title) [2024-07-09]},
	keywords = {{SNN}, 事件流仿真, gazebo},
	file = {Kaiser 等 - 2016 - Towards a framework for end-to-end control of a si.pdf:D\:\\ProgramData\\Zotero\\storage\\HWXGCR42\\Kaiser 等 - 2016 - Towards a framework for end-to-end control of a si.pdf:application/pdf},
}
@inproceedings{rebecq_esim_2018,
	location = {Zurich, Switzerland},
	title = {{ESIM}: an open event camera simulator},
	abstract = {Event cameras are revolutionary sensors that work radically differently from standard cameras. Instead of capturing intensity images at a ﬁxed rate, event cameras measure changes of intensity asynchronously, in the form of a stream of events, which encode per-pixel brightness changes. In the last few years, their outstanding properties (asynchronous sensing, no motion blur, high dynamic range) have led to exciting vision applications, with very low-latency and high robustness. However, these sensors are still scarce and expensive to get, slowing down progress of the research community. To address these issues, there is a huge demand for cheap, high-quality synthetic, labeled event for algorithm prototyping, deep learning and algorithm benchmarking. The development of such a simulator, however, is not trivial since event cameras work fundamentally differently from framebased cameras. We present the ﬁrst event camera simulator that can generate a large amount of reliable event data. The key component of our simulator is a theoretically sound, adaptive rendering scheme that only samples frames when necessary, through a tight coupling between the rendering engine and the event simulator. We release an open source implementation of our simulator.},
	eventtitle = {2nd Conference on Robot Learning ({CoRL} 2018)},
	pages = {969--982},
	booktitle = {Conference on robot learning},
	publisher = {{PMLR}},
	author = {Rebecq, Henri and Gehrig, Daniel and Scaramuzza, Davide},
	date = {2018},
	langid = {english},
	note = {16 citations (Crossref/title) [2024-07-09]
{titleTranslation}:},
	keywords = {基于视频, 基于相机, 仿真环境, 事件流仿真},
	file = {Rebecq 等 - ESIM an Open Event Camera Simulator.pdf:D\:\\ProgramData\\Zotero\\storage\\WYSYNZU7\\Rebecq 等 - ESIM an Open Event Camera Simulator.pdf:application/pdf},
}

@article{joubert_event_2021,
	title = {Event camera simulator improvements via characterized parameters},
	volume = {15},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2021.702765/full},
	doi = {10/grr5d8},
	abstract = {It has been more than two decades since the first neuromorphic Dynamic Vision Sensor ({DVS}) sensor was invented, and many subsequent prototypes have been built with a wide spectrum of applications in mind. Competing against state-of-the-art neural networks in terms of accuracy is difficult, although there are clear opportunities to outperform conventional approaches in terms of power consumption and processing speed. As neuromorphic sensors generate sparse data at the focal plane itself, they are inherently energy-efficient, data-driven, and fast. In this work, we present an extended {DVS} pixel simulator for neuromorphic benchmarks which simplifies the latency and the noise models. In addition, to more closely model the behaviour of a real pixel, the readout circuitry is modelled, as this can strongly affect the time precision of events in complex scenes. Using a dynamic variant of the {MNIST} dataset as a benchmarking task, we use this simulator to explore how the latency of the sensor allows it to outperform conventional sensors in terms of sensing speed.},
	pages = {702765},
	journaltitle = {Frontiers in Neuroscience},
	shortjournal = {Front. Neurosci.},
	author = {Joubert, Damien and Marcireau, Alexandre and Ralph, Nic and Jolley, Andrew and Schaik, André van and Cohen, Gregory},
	urldate = {2023-02-13},
	date = {2021-07-27},
	langid = {english},
	note = {16 citations (Crossref/title) [2024-07-09]},
	keywords = {基于视频, 带宽模拟, 噪声模拟, 事件流仿真},
	file = {Joubert 等 - 2021 - Event Camera Simulator Improvements via Characteri.pdf:D\:\\ProgramData\\Zotero\\storage\\EUF25MZS\\Joubert 等 - 2021 - Event Camera Simulator Improvements via Characteri.pdf:application/pdf},
}

@misc{chakravarthi_recent_2024,
	title = {Recent Event Camera Innovations: A Survey},
	url = {http://arxiv.org/abs/2408.13627},
	doi = {10.48550/arXiv.2408.13627},
	shorttitle = {Recent Event Camera Innovations},
	abstract = {Event-based vision, inspired by the human visual system, offers transformative capabilities such as low latency, high dynamic range, and reduced power consumption. This paper presents a comprehensive survey of event cameras, tracing their evolution over time. It introduces the fundamental principles of event cameras, compares them with traditional frame cameras, and highlights their unique characteristics and operational differences. The survey covers various event camera models from leading manufacturers, key technological milestones, and influential research contributions. It explores diverse application areas across different domains and discusses essential real-world and synthetic datasets for research advancement. Additionally, the role of event camera simulators in testing and development is discussed. This survey aims to consolidate the current state of event cameras and inspire further innovation in this rapidly evolving field. To support the research community, a {GitHub} page (https://github.com/chakravarthi589/Event-based-Vision\_Resources) categorizes past and future research articles and consolidates valuable resources.},
	number = {{arXiv}:2408.13627},
	publisher = {{arXiv}},
	author = {Chakravarthi, Bharatesh and Verma, Aayush Atul and Daniilidis, Kostas and Fermuller, Cornelia and Yang, Yezhou},
	urldate = {2024-10-14},
	date = {2024-08-27},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2408.13627 [cs]},
	note = {{TLDR}: A comprehensive survey of event cameras is presented, tracing their evolution over time, and introduces the fundamental principles of event cameras, compares them with traditional frame cameras, and highlights their unique characteristics and operational differences.},
	keywords = {/unread, 综述, /有待精读},
	file = {PDF:D\:\\ProgramData\\Zotero\\storage\\8CXL98R4\\Chakravarthi 等 - 2024 - Recent Event Camera Innovations A Survey.pdf:application/pdf},
}
